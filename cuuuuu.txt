import os
import json
import time
import pandas as pd
import asyncio
from datetime import datetime
from sqlalchemy.exc import SQLAlchemyError
from sqlalchemy import func, and_,select, BIGINT, create_engine, Column, update, Integer, cast, String, MetaData, DateTime, Float, Text, DECIMAL, TIMESTAMP, text
from sqlalchemy.orm import Session, declarative_base
from df_database_models.db_conn import get_rds_db_session, get_as400_db_session
from df_database_models.models import (
    Customer_Contact, Customer, Source_System
)
from df_database_models.db_utils import (
    generate_uuid, convert_timestamps, query_update_dict, get_record, multi_filter_get_record
)
from secrets_manager import get_secret
from adf_pyutils.clm_wrapper import common_logger

# ... (rest of env vars as before)

pnc_db = os.environ['RDS_DB_NAME']
ref_db = os.environ['RDS_REF_DB_NAME']
mdm_raw_db = os.environ['RDS_RAW_DB_NAME']
mdm_refined_db = os.environ['RDS_REFINED_DB_NAME']

# --- Async Logger Wrapper ---
async def log_msg(func, **kwargs):
    await asyncio.to_thread(func, **kwargs)

# (msg_to_sqs and init_sp unchanged for brevity)

# --- Session/Engine Initializer ---
def call_session_engine(source_system=None, database_name=None):

    rds_secret_name = os.environ["RDS_SECRETS_MANAGER_ID"]
    region_name = os.environ["AWS_REGION"]
    rds_host_nm = os.environ['RDS_HOST']

    if database_name == 'ref_data':
        rds_db_nm = os.environ['RDS_REF_DB_NAME']
    elif database_name == 'mdm_raw':
        rds_db_nm = os.environ['RDS_RAW_DB_NAME']
    elif database_name == 'mdm_refined':
        rds_db_nm = os.environ['RDS_REFINED_DB_NAME']
    else:
        rds_db_nm = os.environ['RDS_DB_NAME']

    if source_system and source_system.lower() == 'as400_aff':
        as400_secret_name = os.environ["AS400_AFF_SECRETS_MANAGER_ID"]
        as400_engine = get_as400_db_session(as400_secret_name, region_name)
        return as400_engine

    elif source_system and source_system.lower() == 'as400_kkins':
        as400_secret_name = os.environ["AS400_KKINS_SECRETS_MANAGER_ID"]
        as400_engine = get_as400_db_session(as400_secret_name, region_name)
        return as400_engine

    if database_name:
        session = get_rds_db_session(rds_secret_name, region_name, rds_host_nm, rds_db_nm)
        return session


# --- Global Sessions ---
session = call_session_engine(database_name=pnc_db)
as400_engine_aff = call_session_engine(source_system='as400_aff')
as400_engine_kkins = call_session_engine(source_system='as400_kkins')
as400_engine_attorney = call_session_engine(source_system='as400_attorney')


# --- Lookup Customer from AS400 ---
def lookup_as400_customer_contact(config=None, id=None):
    """
    Query AS400 systems (AFF / KKINS) for customer record.
    You can adjust the column mappings as per AS400 schema.
    """
    source_system = config.get("source_system")
    df = None

    if source_system and source_system.lower() == "as400_aff":
        df = pd.read_sql(f"""
            SELECT DISTINCT CASt(NULL AS varchar(36)) AS df_customer_contact_id,
            cu.CUSKEY AS source_customer_contact_id,
            CAST(NULL AS varchar(36)) AS df_customer_id,
            CAST(NULL AS varchar(36)) AS df_source_system_id,
            CAST(NULL AS varchar(36)) AS mdm_customer_id,
            CAST(NULL AS timestamp) AS created_date,
            CAST(NULL AS timestamp) AS modified_date
            FROM ADGDTADV.NSOCVGP AS pol
            INNER JOIN ADGDTADV.HCPCSTP AS cust ON pol.customer_no = cust.CUSTNO
            INNER JOIN ADGDTADV.HCPCUSP cu ON cust.CSTKEY = cu.CUSKEY
            WHERE pol.POLICY_TYPE = 'I' and cu.CUSKEY = {id};
        """, con=as400_engine_aff)

    elif source_system and source_system.lower() == "as400_kkins":
        df = pd.read_sql(f"""
            SELECT DISTINCT
                C.CUST_NO AS source_customer_id,
                C.CUST_NAME AS customer_name,
                C.DBA_NAME AS dba_name,
                C.TAX_ID AS tax_number,
                C.EMAIL AS email,
                C.ADDR1 AS premises_address_line_1,
                C.CITY AS premises_city,
                C.STATE AS premises_state,
                C.ZIP AS premises_zip,
                C.PHONE AS premises_phone,
                C.STATUS AS status,
                C.CREATED_TS AS created_ts,
                C.UPDATED_TS AS modified_ts
            FROM KKINSDB.CUSTOMER C
            WHERE C.CUST_NO = '{id}'
        """, con=as400_engine_kkins)

    if df is not None and len(df) > 0:
        return df.to_dict("records")[0]
    return None

# --- Core Consumer ---
async def consume_lambda(config=None):
    print("STEP 1: consume_lambda started")
    start_timestamp = datetime.timestamp(datetime.now())

    try:
        # Parse configs
        if isinstance(config, dict):
            config_list = [config]
        elif isinstance(config, list):
            config_list = config
        else:
            config_list = json.loads(str(config))
            if not isinstance(config_list, list):
                config_list = [config_list]

        print("STEP 2: Processing configs...")

        for config_dict in config_list:
            contact_id = config_dict.get("source_customer_contact_id")
            source_system = config_dict.get("source_system", "").lower()

            print(f"STEP 2.1: Processing contact_id={contact_id}, source_system={source_system}")

            # AS400 Lookup
            as400_engine = as400_engine_aff if source_system == "as400_aff" else as400_engine_kkins
            as400_contact = lookup_as400_customer_contact(config_dict, contact_id)
            print("AS400 Contact:", as400_contact)
            if not as400_contact:
                print(f"[ERROR] No AS400 record found for customer_contact={contact_id}")
                continue

            # --- Source_System Upsert ---
            ss_query = multi_filter_get_record(session, model=Source_System, source_system=source_system)
            ss_record = ss_query.first() if ss_query else None
            if not ss_record:
                df_source_system_id = generate_uuid(str(source_system), "SourceSystem")
                source_system_dict = {
                    "source_system": source_system,
                    "df_source_system_id": df_source_system_id
                }
                session.add(Source_System.from_dict(cls=Source_System, d=source_system_dict))
                session.commit()
                print(f"Inserted new Source_System: {source_system}")
                as400_contact["df_source_system_id"] = df_source_system_id
            else:
                as400_contact["df_source_system_id"] = ss_record.df_source_system_id

            df_source_system_id = as400_contact["df_source_system_id"]

            # --- Customer Upsert ---
            src_customer_id = as400_contact.get("source_customer_contact_id")
            customer_record = session.query(Customer).filter(
                Customer.source_customer_id == src_customer_id,
                Customer.df_source_system_id == df_source_system_id
            ).first()

            if customer_record:
                as400_contact["df_customer_id"] = customer_record.df_customer_id
                print(f"Customer already exists with df_customer_id {customer_record.df_customer_id}")
            else:
                df_customer_id = generate_uuid(str(src_customer_id or ''), str(df_source_system_id))
                as400_contact["df_customer_id"] = df_customer_id

                # Paranoia check by PK
                existing_uuid = session.query(Customer).filter(
                    Customer.df_customer_id == df_customer_id
                ).first()
                if not existing_uuid:
                    session.add(Customer.from_dict(cls=Customer, d=as400_contact))
                    session.commit()
                    print(f"Inserted new customer {src_customer_id} with df_customer_id {df_customer_id}")
                else:
                    print(f"Customer already exists by PK with df_customer_id {existing_uuid.df_customer_id}")
                    as400_contact["df_customer_id"] = existing_uuid.df_customer_id

            # --- Customer_Contact Upsert ---
            contact_record = session.query(Customer_Contact).filter(
                Customer_Contact.source_customer_contact_id == as400_contact.get("source_customer_contact_id"),
                Customer_Contact.df_customer_id == as400_contact.get("df_customer_id"),
                Customer_Contact.df_source_system_id == as400_contact.get("df_source_system_id")
            ).first()

            if contact_record:
                print(f"Customer_Contact already exists with df_customer_contact_id {contact_record.df_customer_contact_id}")
                # contact_record.update(query_update_dict(obj=Customer_Contact, dict=as400_contact))
                # session.commit()
                print(f"Updated existing Customer_Contact {contact_record.df_customer_contact_id}")
            else:
                uuid_key = (
                    str(as400_contact.get("source_customer_contact_id") or '') +
                    str(as400_contact.get("df_customer_id") or '') +
                    str(as400_contact.get("df_source_system_id") or '')
                )
                df_customer_contact_id = generate_uuid(uuid_key, str(df_source_system_id))
                as400_contact["df_customer_contact_id"] = df_customer_contact_id

                # Paranoia check by PK
                existing_contact_uuid = session.query(Customer_Contact).filter(
                    Customer_Contact.df_customer_contact_id == df_customer_contact_id
                ).first()
                if not existing_contact_uuid:
                    session.add(Customer_Contact.from_dict(cls=Customer_Contact, d=as400_contact))
                    session.commit()
                    print(f"Inserted new Customer_Contact {contact_id} with df_customer_contact_id {df_customer_contact_id}")
                else:
                    print(f"Customer_Contact already exists by PK with df_customer_contact_id {existing_contact_uuid.df_customer_contact_id}")
                    as400_contact["df_customer_contact_id"] = existing_contact_uuid.df_customer_contact_id

        end_timestamp = datetime.timestamp(datetime.now())
        print(f"STEP 10: Finished ingestion. Total time: {end_timestamp - start_timestamp}s")
        return {'execution_time_sec': end_timestamp - start_timestamp}

    except SQLAlchemyError as e:
        session.rollback()
        print("[DB ERROR]", str(e))
        raise e


# --- Lambda Handler ---
def handle(event, context):
    start_time = time.time()
    print("Handle function is called for customer_contact ingestion")
    for record in event['Records']:
        payload = record["body"]
        asyncio.run(consume_lambda(config=payload))
    return {"execution_time_sec": time.time() - start_time}

# if __name__ == "__main__":
#     # sample test event (adjust source_system and contact id as needed)
#     test_event = {
#         "Records": [
#             {"body": '{"source_customer_contact_id":"4000341469","source_system":"as400_aff"}'}
#         ]
#     }
#     handle(test_event, None)




{'source_invoice_id': '461562702-20010525-853259', 'source_line_item_id': '461562702-20010525-853259_bp', 'source_line_item_type': 'base_premium', 'description': 'Base Premium', 'amount': 89.0}
handle({"Records": [{"body": '{"source_line_item_id":"461561106","source_system":"as400_aff"}'}]}, None)

if contact_record:
                print(f"Line_Item already exists with df_line_item_id {contact_record.df_line_item_id}")
                # If you want to update existing fields, use query_update_dict or manual assignment + commit
                # contact_record.update(query_update_dict(obj=Line_Item, dict=as400_line_item))
                # session.commit()
                print(f"Updated existing Line_Item {contact_record.df_line_item_id}")
            else:
                # create composite UUID key similar to your contact code
                uuid_key = (
                    str(as400_line_item.get("source_line_item_id") or '') +
                    str(as400_line_item.get("df_invoice_id") or '') +
                    str(as400_line_item.get("df_source_system_id") or '')
                )
                df_line_item_id = generate_uuid(uuid_key, str(df_source_system_id))
                as400_line_item["df_line_item_id"] = df_line_item_id

                # Paranoia check by PK
                existing_line_uuid = session.query(Line_Item).filter(
                    Line_Item.df_line_item_id == df_line_item_id
                ).first()
                if not existing_line_uuid:
                    # Map fields that the Line_Item model expects. Add/adjust fields as per your model definition.
                    print('IUnside if &&&&&&&&&&&&&&&&&&&&********************************************')
                    print(as400_line_item)
                    print('IUnside if &&&&&&&&&&&&&&&&&&&&********************************************')
                    print(df_line_item_id)
                    print('IUnside if &&&&&&&&&&&&&&&&&&&&********************************************')
                    line_item_dict = {
                        "df_line_item_id": df_line_item_id,
                        "source_line_item_id": as400_line_item.get("source_line_item_id"),
                        "df_invoice_id": as400_line_item.get("df_invoice_id"),
                        "df_line_item_type_id": as400_line_item.get("df_line_item_type_id"),
                        "df_source_system_id": as400_line_item.get("df_source_system_id"),
                        "description": as400_line_item.get("description"),
                        "amount": as400_line_item.get("amount"),
                        "created_date": datetime.now()
                    }
                    session.add(Line_Item.from_dict(cls=Line_Item, d=line_item_dict))
                    session.commit()
                    print(f"Inserted new Line_Item {source_line_item_id} with df_line_item_id {df_line_item_id}")
                else:
                    print(f"Line_Item already exists by PK with df_line_item_id {existing_line_uuid.df_line_item_id}")
                    as400_line_item["df_line_item_id"] = existing_line_uuid.df_line_item_id



IUnside if &&&&&&&&&&&&&&&&&&&&********************************************
{'source_invoice_id': '461562702-20010525-853259', 'source_line_item_id': '461562702-20010525-853259_bp', 'source_line_item_type': 'base_premium', 'description': 'Base Premium', 'amount': 89.0, 'df_source_system_id': 12, 'df_invoice_id': '222ab7b8-5969-5e78-b7c0-7874f508df5e', 'df_line_item_type_id': 'be8c5d0a-6872-5161-b13e-7e180bb833bf', 'df_line_item_id': 'ae773f66-3aa0-5efe-8325-3488f92c35ce'}
IUnside if &&&&&&&&&&&&&&&&&&&&********************************************
ae773f66-3aa0-5efe-8325-3488f92c35ce
IUnside if &&&&&&&&&&&&&&&&&&&&********************************************
[DB ERROR] (pymysql.err.IntegrityError) (1452, 'Cannot add or update a child row: a foreign key constraint fails (`pnc_warehouse`.`line_item`, CONSTRAINT `line_item_ibfk_2` FOREIGN KEY (`df_line_item_type_id`) REFERENCES `line_item_type` (`df_line_item_type_id`))')
[SQL: INSERT INTO line_item (df_line_item_id, df_invoice_id, df_line_item_type_id, source_line_item_id, source_line_item_type, description, amount, df_source_system_id) VALUES (%(df_line_item_id)s, %(df_invoice_id)s, %(df_line_item_type_id)s, %(source_line_item_id)s, line_item.source_line_item_type, %(description)s, %(amount)s, %(df_source_system_id)s)]
[parameters: {'df_line_item_id': 'ae773f66-3aa0-5efe-8325-3488f92c35ce', 'df_invoice_id': '222ab7b8-5969-5e78-b7c0-7874f508df5e', 'df_line_item_type_id': 'be8c5d0a-6872-5161-b13e-7e180bb833bf', 'source_line_item_id': '461562702-20010525-853259_bp', 'description': 'Base Premium', 'amount': 89.0, 'df_source_system_id': 12}]
(Background on this error at: https://sqlalche.me/e/20/gkpj)
Traceback (most recent call last):
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\sqlalchemy\engine\base.py", line 1963, in _exec_single_context
    self.dialect.do_execute(
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\sqlalchemy\engine\default.py", line 943, in do_execute
    cursor.execute(statement, parameters)
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\pymysql\cursors.py", line 153, in execute
    result = self._query(query)
             ^^^^^^^^^^^^^^^^^^
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\pymysql\connections.py", line 563, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\pymysql\connections.py", line 825, in _read_query_result
    result.read()
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\pymysql\connections.py", line 1199, in read
    first_packet = self.connection._read_packet()
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\pymysql\connections.py", line 775, in _read_packet
    packet.raise_for_error()
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\pymysql\protocol.py", line 219, in raise_for_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\A0885080\AppData\Roaming\Python\Python312\site-packages\pymysql\err.py", line 150, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.IntegrityError: (1452, 'Cannot add or update a child row: a foreign key constraint fails (`pnc_warehouse`.`line_item`, CONSTRAINT `line_item_ibfk_2` FOREIGN KEY (`df_line_item_type_id`) REFERENCES `line_item_type` (`df_line_item_type_id`))')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
